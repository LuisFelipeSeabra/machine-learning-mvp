# MVP - Machine learning

## Descri√ß√£o do conjunto de dados üìú

Este conjunto de dados oferece uma variedade de atributos valiosos para uma an√°lise abrangente. 
Ele cont√©m 555.719 inst√¢ncias e 22 atributos, uma mistura de tipos de dados categ√≥ricos e num√©ricos. 
√â importante ressaltar que o conjunto de dados est√° completo sem valores nulos.
Aqui est√° uma an√°lise dos atributos:

* Trans_date_trans_time:Timestamp da transa√ß√£o (data e hora).
* Cc_num: N√∫mero de identifica√ß√£o exclusivo do cliente.
* Comerciante: O comerciante envolvido na transa√ß√£o.
* Categoria: Tipo de transa√ß√£o (por exemplo, pessoal, assist√™ncia infantil).
* Valor: Valor da transa√ß√£o.
* Primeiro: Primeiro nome do titular do cart√£o.
* Sobrenome do titular do cart√£o.
* G√™nero: g√™nero do titular do cart√£o.
* Rua: Endere√ßo do titular do cart√£o.
* Cidade: Cidade de resid√™ncia do titular do cart√£o.
* Estado: Estado de resid√™ncia do titular do cart√£o.
* CEP: CEP do titular do cart√£o.
* Lat: Latitude da localiza√ß√£o do titular do cart√£o.
* Long: Longitude da localiza√ß√£o do titular do cart√£o.
* City_pop: Popula√ß√£o da cidade do titular do cart√£o.
* Cargo: Cargo do titular do cart√£o.
* Dob: Data de nascimento do titular do cart√£o.
* Trans_num: identificador exclusivo da transa√ß√£o.
* Unix_time: carimbo de data/hora da transa√ß√£o (formato Unix).
* Merch_lat:Localiza√ß√£o do comerciante (latitude).
* Merch_long: localiza√ß√£o do comerciante (longitude).
* Is_fraud: Indicador de transa√ß√£o fraudulenta (1 = fraude, 0 = leg√≠tima). Esta √© a vari√°vel alvo para fins de classifica√ß√£o.

## Prepara√ß√£o de Dados ‚òïÔ∏è

Utilizou-se algumas t√©cnicas, durante o projeto, como:
#### One-hot Encoding
O One-Hot Encoding √© uma t√©cnica de pr√©-processamento de dados que converte vari√°veis categ√≥ricas em bin√°rios. Em outras palavras, ele cria uma nova coluna para cada valor √∫nico presente na vari√°vel categ√≥rica e atribui o valor 1 √† coluna correspondente ao valor presente e 0 no resto das colunas

#### Label  Encoding
Label Encoding consiste em converter as classes categ√≥ricas em n√∫meros que as representam (ex: masculino/feminino s√£o convertidos em 0/1, Brasil/EUA/Jap√£o ser√£o convertidos em 0/1/2, etc.). 

#### Balancemaneto da base com SMOTE
A SMOTE (t√©cnica de sobreamostragem minorit√°ria sint√©tica) √© uma t√©cnica estat√≠stica para aumentar o n√∫mero de casos em seu conjunto de um modo equilibrado. O componente funciona gerando novas inst√¢ncias de casos minorit√°rios existentes que voc√™ fornece como entrada.

#### Transformacao de datas de anivers√°rio em idade

## Modelagem e treinamento üéâ

Foram utilizados os seguintes para treinar e testar:

modelo_knn = dict(nome = "KNN", modelo = KNeighborsClassifier())
modelo_cart = dict(nome = "CART", modelo = DecisionTreeClassifier())
modelo_nb = dict(nome = "NB", modelo = GaussianNB())
modelo_svm = dict(nome = "SVM", modelo = SVC())

Divisao da base entre teste e treino foi de 80/20

#### Utilizamos validacao cruzada:
Na valida√ß√£o cruzada k-fold, voc√™ divide os dados de entrada em subconjuntos de dados k (tamb√©m chamados de folds). Voc√™ treina um modelo de ML em todos, menos em um (k-1) dos conjuntos de dados e, em seguida, avalia o modelo no conjunto de dados que n√£o foi usado para treinamento.

## Avalia√ß√£o de Resultados ü¶Ñ


#### One-hot Encoder
Utilizando one hot encoder, atingimos os seguintes valores de treino:
KNN: 0.996064 (0.000072)
CART: 0.996720 (0.000045)!
NB: 0.939459 (0.000839)
SVM: 0.996084 (0.000097)

J√° para testes:
Acur√°cio do modelo KNN: 0.996014
Acur√°cio do modelo CART: 0.996869!
Acur√°cio do modelo NB: 0.940393
Acur√°cio do modelo SVM: 0.996293


#### Label Encoder
Utilizando label encoder, atingimos os seguintes valores de treino:
KNN: 0.996156 (0.000061)
CART: 0.996648 (0.000094)!
NB: 0.992168 (0.000859)
SVM: 0.996082 (0.000094)

J√° para testes:
Acur√°cio do modelo KNN: 0.996257
Acur√°cio do modelo CART: 0.996779!
Acur√°cio do modelo NB: 0.992559
Acur√°cio do modelo SVM: 0.996284


#### SMOTE + label encoder
Utilizando SMOTE para balancear a base, atingimos os seguintes valores de treino:
KNN: 0.986253 (0.000079)
CART: 0.988424 (0.000028)!
NB: 0.814953 (0.003902)

J√° para testes:
Acur√°cio do modelo KNN: 0.980197
Acur√°cio do modelo CART: 0.988169!
Acur√°cio do modelo NB: 0.976373


## Conclus√£o üî•

Em todos os testes e treinamentos, CART obteve a maior acur√°cia!

Por√©m KNN(utilizando SMOTE) conseguiu o melhor desempenho em encontrar fraudes(357), em contrapartida, apresentou muitos falsos positivos(2132). 
Esse modelo previu, corretamente, que 108586 casos n√£o eram fraudes e errou apenas 69(falso negativo).

J√° o Cart(one-hot encoder), com acur√°cia de 0.996869, encontrou 252 fraudes e apresentou poucos falsos positivos(174).
Esse modelo previu, corretamente, que 110544 casos n√£o eram fraudes e encontrou 174 falsos negativos.

A melhor opcao encontrada para evitar fraudes foi o KNN(utilizando Smote), uma vez que conseguiu prever o maior numero de fraudes, cerca de 357 casos.
Apesar da quantidade de falsos positivos, o modelo foi o que mais previu fraudes e o que menos apresentou casos falso negativo: 69.